{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aruntakhur/SitareUniversity/blob/main/MinMax_Search_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btd5ixFj6Bv5"
      },
      "source": [
        "# Lab Assignment: Tic Tac Toe with Minimax Search\n",
        "\n",
        "## Objective\n",
        "In this lab, you will:\n",
        "- Implement Tic Tac Toe using Python.\n",
        "- Write state functions (`S0`, `Player`, `Actions`, `Result`, `Terminal`, `Utility`).\n",
        "- Implement the **Minimax algorithm**.\n",
        "- Count the number of states evaluated.\n",
        "- Compare theoretical vs actual states explored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kz7sExzS56jF"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Part A: State Representation\n",
        "# -----------------------------\n",
        "\n",
        "# Initial state (S0): empty 3x3 board\n",
        "S0 = [\" \" for _ in range(9)]\n",
        "\n",
        "\n",
        "def print_board(state):\n",
        "    \"\"\"Print the board in a 3x3 format\"\"\"\n",
        "    print(state[0]+\"|\"+state[1]+\"|\"+state[2])\n",
        "    print(\"-+-+-\")\n",
        "    print(state[3]+\"|\"+state[4]+\"|\"+state[5])\n",
        "    print(\"-+-+-\")\n",
        "    print(state[6]+\"|\"+state[7]+\"|\"+state[8])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fwonz2Ud6Mx0"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# TODO Part A: Implement State Functions\n",
        "# -----------------------------\n",
        "\n",
        "def Player(state):\n",
        "    \"\"\"Return which player has the next turn\"\"\"\n",
        "    # TODO: Implement using counts of X and O\n",
        "    x_count = state.count(\"X\")\n",
        "    o_count = state.count(\"O\")\n",
        "    return \"X\" if x_count == o_count else \"O\"\n",
        "\n",
        "\n",
        "def Actions(state):\n",
        "    \"\"\"Return list of legal moves\"\"\"\n",
        "    # TODO: Return all indexes that are still empty\n",
        "    return [i for i, cell in enumerate(state) if cell == \" \"]\n",
        "    \n",
        "\n",
        "\n",
        "def Result(state, action):\n",
        "    \"\"\"Return new state after action is taken\"\"\"\n",
        "    # TODO: Copy the state and apply the move\n",
        "    new_state = state.copy()\n",
        "    new_state[action] = Player(state)\n",
        "    return new_state\n",
        "\n",
        "\n",
        "def Terminal(state):\n",
        "    \"\"\"Return True if the state is terminal (win or draw)\"\"\"\n",
        "    # TODO: Check for win or if no moves left\n",
        "    wins = [\n",
        "        [0,1,2], [3,4,5], [6,7,8],  # rows\n",
        "        [0,3,6], [1,4,7], [2,5,8],  # columns\n",
        "        [0,4,8], [2,4,6]            # diagonals\n",
        "    ]\n",
        "    for combo in wins:\n",
        "        if state[combo[0]] != \" \" and state[combo[0]] == state[combo[1]] == state[combo[2]]:\n",
        "            return True  # win\n",
        "    if \" \" not in state:\n",
        "        return True  # draw\n",
        "    return False\n",
        "    \n",
        "\n",
        "\n",
        "def Utility(state):\n",
        "    \"\"\"Return +1 if X wins, -1 if O wins, else 0\"\"\"\n",
        "    # TODO: Implement win/draw logic\n",
        "    wins = [\n",
        "        [0,1,2], [3,4,5], [6,7,8],  # rows\n",
        "        [0,3,6], [1,4,7], [2,5,8],  # columns\n",
        "        [0,4,8], [2,4,6]            # diagonals\n",
        "    ]\n",
        "    for combo in wins:\n",
        "        if state[combo[0]] != \" \" and state[combo[0]] == state[combo[1]] == state[combo[2]]:\n",
        "            return 1 if state[combo[0]] == \"X\" else -1\n",
        "    return 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rnBBSH8o6Rhh"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Part B: Minimax Implementation\n",
        "# -----------------------------\n",
        "\n",
        "\n",
        "def MAX_VALUE(state):\n",
        "\n",
        "    if Terminal(state):\n",
        "        return Utility(state)\n",
        "\n",
        "    v = float(\"-inf\")\n",
        "    for action in Actions(state):\n",
        "        v = max(v, MIN_VALUE(Result(state, action)))\n",
        "    return v\n",
        "\n",
        "\n",
        "def MIN_VALUE(state):\n",
        "\n",
        "    if Terminal(state):\n",
        "        return Utility(state)\n",
        "\n",
        "    v = float(\"inf\")\n",
        "    for action in Actions(state):\n",
        "        v = min(v, MAX_VALUE(Result(state, action)))\n",
        "    return v\n",
        "\n",
        "\n",
        "def minimax_decision(state):\n",
        "    \"\"\"Return best move for current player\"\"\"\n",
        "    global call_count\n",
        "    call_count = 0\n",
        "\n",
        "    player = Player(state)\n",
        "    best_move = None\n",
        "\n",
        "    if player == \"X\":\n",
        "        best_val = float(\"-inf\")\n",
        "        for action in Actions(state):\n",
        "            val = MIN_VALUE(Result(state, action))\n",
        "            if val > best_val:\n",
        "                best_val = val\n",
        "                best_move = action\n",
        "    else:\n",
        "        best_val = float(\"inf\")\n",
        "        for action in Actions(state):\n",
        "            val = MAX_VALUE(Result(state, action))\n",
        "            if val < best_val:\n",
        "                best_val = val\n",
        "                best_move = action\n",
        "\n",
        "    return best_move\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MzX_7U456h-E"
      },
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Part C: Human vs AI Game\n",
        "# -----------------------------\n",
        "\n",
        "# Add Code to detect invalid move also\n",
        "\n",
        "def play():\n",
        "    state = S0.copy()\n",
        "\n",
        "    while not Terminal(state):\n",
        "        print_board(state)\n",
        "        if Player(state) == \"X\":  # Human move\n",
        "            move = int(input(\"Enter your move (1-9): \")) - 1\n",
        "\n",
        "        else:  # AI move\n",
        "            print(\"AI is thinking...\")\n",
        "            move = minimax_decision(state)\n",
        "\n",
        "        state = Result(state, move)\n",
        "\n",
        "    print_board(state)\n",
        "    if Utility(state) == 1:\n",
        "        print(\"X wins!\")\n",
        "    elif Utility(state) == -1:\n",
        "        print(\"O wins!\")\n",
        "    else:\n",
        "        print(\"It's a draw!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Part D: Minimax with Alpha-Beta Pruning\n",
        "# -----------------------------\n",
        "\n",
        "def MAX_VALUE_AB(state, alpha, beta):\n",
        "    if Terminal(state):\n",
        "        return Utility(state)\n",
        "    \n",
        "    v = float(\"-inf\")\n",
        "    for action in Actions(state):\n",
        "        v = max(v, MIN_VALUE_AB(Result(state, action), alpha, beta))\n",
        "        if v >= beta:\n",
        "            return v\n",
        "        alpha = max(alpha, v)\n",
        "    return v\n",
        "\n",
        "\n",
        "def MIN_VALUE_AB(state, alpha, beta):\n",
        "    if Terminal(state):\n",
        "        return Utility(state)\n",
        "    \n",
        "    v = float(\"inf\")\n",
        "    for action in Actions(state):\n",
        "        v = min(v, MAX_VALUE_AB(Result(state, action), alpha, beta))\n",
        "        if v <= alpha:\n",
        "            return v\n",
        "        beta = min(beta, v)\n",
        "    return v\n",
        "\n",
        "\n",
        "def minimax_ab_decision(state):\n",
        "    \"\"\"Return best move using minimax with alpha-beta pruning.\"\"\"\n",
        "    player = Player(state)\n",
        "    best_move = None\n",
        "    \n",
        "    if player == \"X\":\n",
        "        best_val = float(\"-inf\")\n",
        "        alpha, beta = float(\"-inf\"), float(\"inf\")\n",
        "        for action in Actions(state):\n",
        "            val = MIN_VALUE_AB(Result(state, action), alpha, beta)\n",
        "            if val > best_val:\n",
        "                best_val = val\n",
        "                best_move = action\n",
        "            alpha = max(alpha, best_val)\n",
        "    else:\n",
        "        best_val = float(\"inf\")\n",
        "        alpha, beta = float(\"-inf\"), float(\"inf\")\n",
        "        for action in Actions(state):\n",
        "            val = MAX_VALUE_AB(Result(state, action), alpha, beta)\n",
        "            if val < best_val:\n",
        "                best_val = val\n",
        "                best_move = action\n",
        "            beta = min(beta, best_val)\n",
        "    \n",
        "    return best_move\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0aDwYO57PnU"
      },
      "source": [
        "# -----------------------------\n",
        "# Part D: Experiment and Analysis\n",
        "# -----------------------------\n",
        "\n",
        "1. Run the game where X plays first in the center (position 5).\n",
        "2. Note down the number of states AI explored.\n",
        "3. Compare with:\n",
        "   - 8! = 40,320 (leaf-only sequences)\n",
        "   - 8+8â‹…7+8â‹…7â‹…6+â‹¯+8! = 109,600 (all partial states)\n",
        "4. Explain why actual count (~55,504) is smaller than 109,600.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----------------------------\n",
        "# Part E: Human vs AI Game (with Alpha-Beta)\n",
        "# -----------------------------\n",
        "\n",
        "def play_ab():\n",
        "    state = S0.copy()\n",
        "    \n",
        "    while not Terminal(state):\n",
        "        print_board(state)\n",
        "        \n",
        "        if Player(state) == \"X\":  # Human move\n",
        "            try:\n",
        "                move = int(input(\"Enter your move (1-9): \")) - 1\n",
        "                if move not in Actions(state):\n",
        "                    print(\"âŒ Invalid move, try again.\")\n",
        "                    continue\n",
        "            except ValueError:\n",
        "                print(\"âŒ Please enter a number between 1 and 9.\")\n",
        "                continue\n",
        "        else:  # AI move with alpha-beta\n",
        "            print(\"ðŸ¤– AI (Alpha-Beta) is thinking...\")\n",
        "            move = minimax_ab_decision(state)\n",
        "            print(\"AI chooses position:\", move+1)\n",
        "\n",
        "        state = Result(state, move)\n",
        "\n",
        "    # Final board and result\n",
        "    print_board(state)\n",
        "    if Utility(state) == 1:\n",
        "        print(\"ðŸŽ‰ X wins!\")\n",
        "    elif Utility(state) == -1:\n",
        "        print(\"ðŸ¤– O wins!\")\n",
        "    else:\n",
        "        print(\"ðŸ¤ It's a draw!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " | | \n",
            "-+-+-\n",
            " | | \n",
            "-+-+-\n",
            " | | \n",
            " | | \n",
            "-+-+-\n",
            " |X| \n",
            "-+-+-\n",
            " | | \n",
            "ðŸ¤– AI is thinking...\n",
            "AI chooses position: 1\n",
            "O| | \n",
            "-+-+-\n",
            " |X| \n",
            "-+-+-\n",
            " | | \n",
            "O| | \n",
            "-+-+-\n",
            " |X| \n",
            "-+-+-\n",
            " |X| \n",
            "ðŸ¤– AI is thinking...\n",
            "AI chooses position: 2\n",
            "O|O| \n",
            "-+-+-\n",
            " |X| \n",
            "-+-+-\n",
            " |X| \n",
            "O|O|X\n",
            "-+-+-\n",
            " |X| \n",
            "-+-+-\n",
            " |X| \n",
            "ðŸ¤– AI is thinking...\n",
            "AI chooses position: 7\n",
            "O|O|X\n",
            "-+-+-\n",
            " |X| \n",
            "-+-+-\n",
            "O|X| \n",
            "O|O|X\n",
            "-+-+-\n",
            "X|X| \n",
            "-+-+-\n",
            "O|X| \n",
            "ðŸ¤– AI is thinking...\n",
            "AI chooses position: 6\n",
            "O|O|X\n",
            "-+-+-\n",
            "X|X|O\n",
            "-+-+-\n",
            "O|X| \n",
            "O|O|X\n",
            "-+-+-\n",
            "X|X|O\n",
            "-+-+-\n",
            "O|X|X\n",
            "ðŸ¤ It's a draw!\n"
          ]
        }
      ],
      "source": [
        "play()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FK7ZBl87bWL"
      },
      "source": [
        "# -----------------------------\n",
        "# Part E: Written Questions\n",
        "# -----------------------------\n",
        "\n",
        "Answer briefly:\n",
        "\n",
        "1. Why does Minimax need to evaluate so many states in Tic Tac Toe?\n",
        "2. Difference between full tree size and actual explored states?\n",
        "3. How do early wins reduce the number of states?\n",
        "4. What challenges would arise if applying Minimax to Chess?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNi+yMo94DnUzMTNfgyp2QW",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
